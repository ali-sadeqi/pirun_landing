(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[281],{444:function(e,i,t){Promise.resolve().then(t.t.bind(t,2666,23)),Promise.resolve().then(t.bind(t,4425)),Promise.resolve().then(t.bind(t,8455)),Promise.resolve().then(t.t.bind(t,414,23)),Promise.resolve().then(t.bind(t,2442))},2580:function(e,i,t){"use strict";t.d(i,{M:function(){return n}});var a=t(226),s=t(9128);let n=()=>{a.p8.registerPlugin(s.ScrollTrigger);let e=document.querySelectorAll(".mil-up");e.forEach(e=>{a.p8.fromTo(e,{opacity:0,y:50,scale:.98,ease:"sine"},{y:0,opacity:1,scale:1,scrollTrigger:{trigger:e,toggleActions:"play none none reverse"}})});let i=document.querySelectorAll(".mil-scale");i.forEach(e=>{var i=e.getAttribute("data-value-1"),t=e.getAttribute("data-value-2");a.p8.fromTo(e,{ease:"sine",scale:i},{scale:t,scrollTrigger:{trigger:e,scrub:!0,toggleActions:"play none none reverse"}})});let t=document.querySelectorAll(".mil-parallax");t.forEach(e=>{var i=e.getAttribute("data-value-1"),t=e.getAttribute("data-value-2");a.p8.fromTo(e,{ease:"sine",y:i},{y:t,scrollTrigger:{trigger:e,scrub:!0,toggleActions:"play none none reverse"}})});let n=document.querySelectorAll(".mil-skill-prog");n.forEach(e=>{var i=e.getAttribute("data-value-1"),t=e.getAttribute("data-value-2");a.p8.fromTo(e,{width:i,ease:"sine"},{width:t,duration:2,scrollTrigger:{trigger:e,toggleActions:"play none none reverse"}})});let l=document.querySelectorAll(".mil-counter");l.forEach(e=>{var i=e,t={val:0},s=e.dataset.number,n=(s+"").split("."),l=n.length>1?n[1].length:0;a.p8.to(t,{val:s,duration:2,scrollTrigger:{trigger:e,toggleActions:"play none none reverse"},onUpdate:function(){i.innerHTML=t.val.toFixed(l)}})}),a.p8.to(".mil-progress",{height:"100%",ease:"sine",scrollTrigger:{scrub:.3}});let r=document.querySelector(".mil-top-panel");void 0!=r&&window.addEventListener("scroll",e=>{window.scrollY>10?r.classList.add("mil-active"):r.classList.remove("mil-active")})}},2953:function(e,i,t){"use strict";t.d(i,{M:function(){return s}});var a=t(9682);t(6888),t(2803),t(103),a.ZP.use([a.Gk,a.tl,a.W_,a.xW,a.pt,a.rj,a.gI,a.oM,a.kr,a.Ay,a.o3,a.LW,a.N1,a.s5,a.VS,a.Rv]);let s={milInfiniteSlider:{slidesPerView:1,spaceBetween:0,speed:4e3,autoplay:!0,autoplay:{delay:0},loop:!0,freeMode:!0,breakpoints:{768:{slidesPerView:2},992:{slidesPerView:4}}},milBannerSlider:{slidesPerView:1,spaceBetween:30,speed:800,autoplay:{delay:5e3},effect:"fade",parallax:!0,loop:!0,navigation:{prevEl:".mil-banner-prev",nextEl:".mil-banner-next"},pagination:{el:".mil-banner-pagination",type:"bullets",clickable:!0}},milBannerSlider2:{slidesPerView:1,spaceBetween:30,speed:800,autoplay:{delay:5e3},effect:"fade",parallax:!0,loop:!0,navigation:{prevEl:".mil-banner-prev",nextEl:".mil-banner-next"},pagination:{el:".mil-banner-pagination",type:"bullets",clickable:!0}},milProcessSlider:{slidesPerView:1,spaceBetween:30,speed:800,parallax:!0,navigation:{prevEl:".mil-process-prev",nextEl:".mil-process-next"},pagination:{el:".mil-banner-pagination",type:"bullets",clickable:!0}},milReviewsSlider:{slidesPerView:1,spaceBetween:30,speed:800,effect:"fade",parallax:!0,navigation:{prevEl:".mil-process-prev",nextEl:".mil-process-next"},pagination:{el:".mil-banner-pagination",type:"bullets",clickable:!0}},milIllustrationSlider:{slidesPerView:1,spaceBetween:30,speed:800,effect:"fade",parallax:!0,navigation:{prevEl:".mil-illustration-prev",nextEl:".mil-illustration-next"}}}},8455:function(e,i,t){"use strict";t.r(i),t.d(i,{default:function(){return d}});var a=t(9268),s=JSON.parse('[{"section":"Instance Segmentation","image":{"url":"/img/photo/instance.jpg","alt":"img"},"title":"Instance Segmentation","description":"Our team excels in identifying and delineating individual objects within an image, providing precise boundaries for each instance. For example, in a scene with multiple people, we can accurately segment each person from the background and determine their exact outlines. We employ techniques like Region-based Convolutional Neural Networks (R-CNN), Faster R-CNN, Mask R-CNN, and DeepLab to achieve this.","subSections":[{"title":"R-CNN:","description":"A two-stage approach that first generates region proposals and then classifies and regresses bounding boxes for each proposal."},{"title":"Mask R-CNN","description":"An extension of Faster R-CNN that adds a branch for instance segmentation, predicting a pixel-wise mask for each detected object."},{"title":"Faster R-CNN:","description":"An improved version of R-CNN that introduces a Region Proposal Network (RPN) to efficiently generate region proposals."},{"title":"DeepLab","description":"A fully convolutional network that uses atrous convolution and dilated convolutions to capture multi-scale information and achieve high-resolution segmentation."}]},{"section":"Semantic Segmentation","image":{"url":"/img/photo/semantic.jpg","alt":"img"},"title":"Semantic Segmentation","description":"We specialize in categorizing every pixel in an image into meaningful semantic classes, enabling detailed scene understanding. This allows us to distinguish between different objects and their attributes, such as cars, pedestrians, roads, and buildings. We utilize techniques such as Fully Convolutional Networks (FCNs), U-Net, DeepLab, and PSPNet for semantic segmentation.","subSections":[{"title":"FCNs","description":"A fully convolutional network that replaces fully connected layers with convolutional layers, allowing for end-to-end training and dense pixel-wise predictions."},{"title":"U-Net","description":"An extension of Faster R-CNN that adds a branch for instance segmentation, predicting a pixel-wise mask for each detected object."},{"title":"DeepLab","description":"A fully convolutional network that uses atrous convolution and dilated convolutions to capture multi-scale information and achieve high-resolution segmentation.."},{"title":"PSPNet","description":"A pyramid scene parsing network that incorporates a pyramid pooling module to capture context at different scales."}]},{"section":"Object Detection","image":{"url":"/img/photo/object.jpg","alt":"img"},"title":"Object Detection","description":"Our expertise lies in locating and classifying objects within images or videos, providing accurate bounding boxes and labels. This enables us to identify and track objects of interest, such as vehicles, faces, or animals. We employ techniques like YOLO, SSD, Faster R-CNN, and RetinaNet for object detection","subSections":[{"title":"YOLO","description":"A one-stage detector that divides an image into a grid and predicts bounding boxes and class probabilities for each cell."},{"title":"SSD","description":"A single-shot detector that uses multiple feature maps at different scales to detect objects of various sizes"},{"title":"Faster R-CNN","description":"A two-stage detector that uses a Region Proposal Network (RPN) to efficiently generate region proposals"},{"title":"RetinaNet","description":"A one-stage detector that uses a focal loss function to address class imbalance and improve detection accuracy."}]},{"section":"Depth Estimation","image":{"url":"/img/photo/object.jpg","alt":"img"},"title":"Depth Estimation","description":"We can accurately determine the distance between objects and the camera in a scene, creating a 3D representation from 2D images. This is useful for applications like autonomous driving, augmented reality, and robotics, where understanding the spatial layout of a scene is crucial. We utilize techniques such as stereo matching, monocular depth estimation, and structure from motion for depth estimation.","subSections":[{"title":"Stereo matching","description":"A technique that compares corresponding pixels in two images taken from different viewpoints to estimate depth."},{"title":"Monocular depth estimation","description":"A technique that estimates depth from a single image using cues like occlusion boundaries, vanishing points, and texture gradients"},{"title":"Structure from motion","description":"A technique that reconstructs 3D structure from a sequence of images by estimating camera motion and object motion"}]},{"section":"Depth Estimation Video","video":{"url":"/img/video/Tracking - Pirun.mp4","alt":"img"},"title":"Depth Estimation","description":"Our algorithms can reliably follow and identify objects across multiple frames, enabling continuous tracking and analysis. This is essential for tasks such as surveillance, video analytics, and human-computer interaction. We employ techniques like Correlation Filter Tracking, Kalman Filter, and Deep Learning-based tracking for object tracking.","subSections":[{"title":"Correlation Filter Tracking:","description":"A tracking algorithm that uses correlation filters to efficiently track objects in video sequences."},{"title":"Kalman Filter","description":"A probabilistic framework for estimating the state of a dynamic system from noisy measurements."},{"title":"Deep Learning-based tracking","description":"Tracking algorithms that use deep learning models to learn appearance features and motion patterns of objects"}]},{"section":"Classification","image":{"url":"/img/photo/classification.jpg","alt":"img"},"title":"Classification","description":"We can categorize images or videos into predefined classes, providing accurate and efficient labeling. This is useful for tasks like image sorting, image search, and medical image analysis. We employ techniques such as Convolutional Neural Networks (CNNs), Support Vector Machines (SVMs), and Random Forests for classification.","subSections":[{"title":"CNNs","description":"Neural networks that are specifically designed for processing image data, featuring convolutional layers, pooling layers, and fully connected layers."},{"title":"SVMs","description":"Machine learning algorithms that find a hyperplane to separate data points into different classes."},{"title":"Random Forests","description":"Ensemble learning algorithms that combine multiple decision trees to make predictions."}]},{"section":"Regression","image":{"url":"/img/photo/regression.jpg","alt":"img"},"title":"Regression","description":"Our models can predict continuous numerical values, such as object attributes or measurements. For example, we can estimate the size of an object, its speed, or its orientation. We utilize techniques such as linear regression, neural networks, and random forests for regression.","subSections":[{"title":"Linear regression","description":"A statistical method that models the relationship between a dependent variable and one or more independent variables as a linear equation."},{"title":"Neural networks","description":"A class of machine learning models that are inspired by the structure and function of the human brain"},{"title":"Random forests","description":"Ensemble learning algorithms that combine multiple decision trees to make predictions"}]}]'),n=t(3161),l=t.n(n),r=t(6394),o=t.n(r),c=t(6006);t(9939);let m=()=>{let[e,i]=(0,c.useState)(!1);return(0,c.useEffect)(()=>{i(!0)},[]),console.log(s),(0,a.jsx)(a.Fragment,{children:(0,a.jsx)("section",{children:(0,a.jsxs)("div",{className:"container  mil-p-0-30",children:[(0,a.jsx)("div",{className:"mil-background-grid mil-softened"}),s.map((i,t)=>(0,a.jsxs)("div",{id:i.section,className:"col justify-content-between align-items-center",style:{marginTop:"100px"},children:[(0,a.jsxs)("div",{className:"".concat(i.image?"row":"col"," justify-content-between align-items-center ").concat(t%2==0?"flex-sm-row-reverse":"flex-sm-row"," "),children:[(0,a.jsx)("div",{className:"".concat(i.image?"col-lg-8":"col-lg-10"),children:(0,a.jsxs)("div",{className:"",children:[(0,a.jsx)("h3",{className:"mil-mb-30",dangerouslySetInnerHTML:{__html:i.title}}),(0,a.jsx)("p",{style:{lineHeight:"35px"},className:"mil-up mil-mb-40",dangerouslySetInnerHTML:{__html:i.description}})]})}),(0,a.jsx)("div",{className:"".concat(i.image?"col-lg-4":"col-lg-12"),style:i.image?{}:{display:"flex",flexDirection:"row",justifyContent:"center"},children:(0,a.jsx)("div",{className:"mil-illustration mil-up mil-mb-90",style:i.image?{}:{paddingBottom:"0"},children:(0,a.jsx)("div",{className:"".concat(i.image?"mil-image-frame":"videoContainer"),style:{borderRadius:"4px"},children:i.image?(0,a.jsx)(o(),{src:i.image.url,alt:i.image.alt,width:700,height:700}):e&&(0,a.jsx)(l(),{playsinline:!0,playing:!0,muted:!0,loop:!0,progressInterval:1e3,url:"https://firebasestorage.googleapis.com/v0/b/public-iframe/o/host-videos%2FTracking%20-%20Pirun.mp4?alt=media&token=3468f7e4-62cc-4500-bde5-54161bb40406",className:"z-50"})})})})]}),(0,a.jsx)("div",{style:{display:"flex",flexDirection:"row",flexWrap:"wrap",gap:"10%"},children:i.subSections.map((e,i)=>(0,a.jsxs)("div",{className:"",style:{display:"flex",flexDirection:"column",gap:"10%",width:"45%",marginBottom:"50px"},children:[(0,a.jsx)("h5",{style:{marginBottom:"15px"},children:e.title}),(0,a.jsx)("p",{className:"text-justify",children:e.description})]},i))})]},t))]})})})};var d=m},4425:function(e,i,t){"use strict";t.r(i),t.d(i,{default:function(){return m}});var a=t(9268),s=JSON.parse('{"Md":"/img/photo/1.jpg","TN":"Empowering Innovation with<br/><span class=\\"mil-accent\\">Intelligent </span><br/>Solutions","Oc":"The future","LI":{"p":"/projects","P":"View Projects"},"KT":[{"value":"200","afterValue":"+","label":"Succeeded <br/>Projects"},{"value":"8","afterValue":"","label":"Working <br/>Hours"},{"value":"10","afterValue":"+","label":"Years <br/>Experience"},{"value":"500","afterValue":"+","label":"Active <br/>users"}]}'),n=t(5846),l=t.n(n),r=t(6006),o=t(2580);let c=()=>((0,r.useEffect)(()=>{(0,o.M)()},[]),(0,a.jsx)(a.Fragment,{children:(0,a.jsxs)("section",{className:"mil-banner",children:[(0,a.jsx)("img",{src:s.Md,className:"mil-bg-img mil-scale","data-value-1":".4","data-value-2":"1.4",alt:"image"}),(0,a.jsx)("div",{className:"mil-overlay"}),(0,a.jsxs)("div",{className:"container",children:[(0,a.jsx)("div",{className:"mil-background-grid mil-top-space"}),(0,a.jsx)("div",{className:"mil-banner-content",children:(0,a.jsxs)("div",{className:"row align-items-end",children:[(0,a.jsx)("div",{className:"col-xl-7",children:(0,a.jsxs)("div",{className:"mil-mb-90",children:[(0,a.jsx)("span",{className:"mil-suptitle mil-light mil-upper mil-mb-60",children:s.Oc}),(0,a.jsx)("h1",{className:"mil-upper mil-light",dangerouslySetInnerHTML:{__html:s.TN}}),(0,a.jsx)("p",{style:{color:"white",margin:"20px 40px 60px 0",fontSize:"20px"},className:"mil-mb-60",children:"Welcome to PIRUN, where innovation and expertise converge. As a leading software development team, we pride ourselves on our diverse capabilities, spanning backend development, frontend design, mobile application creation, and cutting-edge AI solutions"}),(0,a.jsxs)(l(),{href:s.LI.p,className:"mil-link mil-light mil-upper",children:[s.LI.P," ",(0,a.jsx)("span",{className:"mil-arrow",children:(0,a.jsx)("img",{src:"img/icons/1.svg",alt:"arrow"})})]})]})}),(0,a.jsx)("div",{className:"col-xl-5",children:(0,a.jsx)("div",{className:"row mil-mb-60",children:s.KT.map((e,i)=>(0,a.jsx)("div",{className:"col-6",children:(0,a.jsxs)("div",{className:"mil-counter-frame mil-light mil-mb-30",children:[(0,a.jsxs)("h4",{className:"mil-accent mil-thin mil-mb-10",children:[(0,a.jsx)("span",{className:"mil-counter","data-number":+e.value,children:"0"}),e.afterValue]}),(0,a.jsx)("p",{className:"mil-light",dangerouslySetInnerHTML:{__html:e.label}})]})},"hero-numbers-item-".concat(i)))})})]})})]})]})}));var m=c},2442:function(e,i,t){"use strict";t.r(i);var a=t(9268),s=t(2953),n=t(9321),l=t(3821);let r=e=>{let{bgStyle:i}=e;return(0,a.jsx)(a.Fragment,{children:(0,a.jsxs)("div",{className:"mil-".concat(i,"-bg mil-partners mil-relative"),children:["soft"==i&&(0,a.jsx)("img",{src:"/img/other/bg.svg",className:"mil-bg-img",alt:"image"}),(0,a.jsxs)("div",{className:"container mil-p-120-120",children:[(0,a.jsx)("div",{className:"mil-background-grid mil-softened"}),(0,a.jsx)(n.tq,{...s.M.milInfiniteSlider,className:"swiper-container mil-infinite-show mil-up",children:l.e.map((e,i)=>(0,a.jsx)(n.o5,{className:"swiper-slide",children:(0,a.jsx)("a",{href:e.link,target:"_blank",className:"mil-partner-frame",style:{width:"60px"},children:(0,a.jsx)("img",{src:e.image,alt:e.alt,style:{width:"100px",height:"100px"}})})},"partners-slider-item-".concat(i)))})]})]})})};i.default=r},3821:function(e){"use strict";e.exports=JSON.parse('{"e":[{"image":"/img/partners/aws.svg","alt":"logo"},{"image":"/img/partners/google-cloud.svg","alt":"logo"},{"image":"/img/partners/swift.svg","alt":"logo"},{"image":"/img/partners/laravel.svg","alt":"logo"},{"image":"/img/partners/tensorflow.svg","alt":"logo"},{"image":"/img/partners/react.svg","alt":"logo"},{"image":"/img/partners/pytorch.svg","alt":"logo"},{"image":"/img/partners/django.svg","alt":"logo"}]}')}},function(e){e.O(0,[8968,3710,9077,6671,8477,2667,8139,1744],function(){return e(e.s=444)}),_N_E=e.O()}]);